{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "hw2_alice_naivebayes_release.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk5Zw48_fJ7Y",
        "outputId": "055f81c1-4720-484d-841e-c09aa58eb3c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_61oNyrfQ-w"
      },
      "source": [
        "import os\n",
        "code_path = \"/content/gdrive/MyDrive/cse512hw2Challenge/\"\n",
        "os.chdir(code_path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtpdHeZjh1pZ"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import random\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5-8LQOzh1pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee054224-eb94-4f90-c949-7c2be498f712"
      },
      "source": [
        "corpus = []\n",
        "f = open('alice_in_wonderland.txt','r')\n",
        "while(1):\n",
        "    line =  f.readline()\n",
        "    if len(line) == 0: break\n",
        "    corpus.extend(line.split())\n",
        "        \n",
        "f.close()\n",
        "corpus = ' '.join(corpus)\n",
        "\n",
        "def clean_word(word):\n",
        "    word = word.lower()\n",
        "    for punctuation in ['\"',\"'\",'.',',','-','?','!',';',':','â€”','(',')','[',']']:\n",
        "        word = word.split(punctuation)[0]\n",
        "    return word\n",
        "\n",
        "\n",
        "\n",
        "corpus = [clean_word(word) for word in corpus.split()]\n",
        "corpus = [word for word in corpus if len(word) > 0]\n",
        "print(corpus[:25])\n",
        "D = len(corpus)\n",
        "print('corpus len: ',D)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alice', 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', 'the', 'millennium', 'fulcrum', 'edition', '3', 'contents', 'chapter', 'i', 'down', 'the', 'rabbit', 'chapter', 'ii', 'the', 'pool', 'of', 'tears', 'chapter']\n",
            "corpus len:  25320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mIUA54nh1pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a8b572-40fd-4b2b-deba-a21facbf29f3"
      },
      "source": [
        "tokenize = {}\n",
        "dictionary = []\n",
        "token = 0\n",
        "for word in corpus:\n",
        "    if word not in tokenize.keys():\n",
        "        tokenize[word] = token\n",
        "        dictionary.append(word)\n",
        "        token += 1\n",
        "    \n",
        "V = len(dictionary)\n",
        "print('dictionary size (number of distinct words): ', V)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dictionary size (number of distinct words):  2501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARyNaN98h1pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1c1a5a-3839-41b3-dcc1-903ad896488a"
      },
      "source": [
        "#past word as feature\n",
        "\n",
        "posterior_1word = np.zeros((V, V))\n",
        "prior = np.zeros(V)\n",
        "# Calculate the prior of the words.\n",
        "for i in range(len(corpus)):\n",
        "    prior[tokenize[corpus[i]]] += 1\n",
        "    if i > 0:\n",
        "       posterior_1word[tokenize[corpus[i-1]]][tokenize[corpus[i]]] += 1\n",
        "\n",
        "posterior_1word = posterior_1word / prior\n",
        "prior = prior / len(corpus)\n",
        "\n",
        "def get_likelihood_2gram(word):\n",
        "    likelihood = posterior_1word[tokenize[word], :] * prior\n",
        "    return(likelihood)\n",
        "def pred_2gram(word):\n",
        "    likelihood = get_likelihood_2gram(word)\n",
        "    i = np.argmax(likelihood)\n",
        "    return(dictionary[i], likelihood[i])\n",
        "print(pred_2gram('alice'))\n",
        "print(pred_2gram('the'))\n",
        "print(pred_2gram('cheshire'))\n",
        "print(pred_2gram('mock'))\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('was', 0.0007109004739336493)\n",
            "('queen', 0.0027646129541864135)\n",
            "('cat', 0.00019747235387045816)\n",
            "('turtle', 0.0022511848341232226)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E4UipUfh1ph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef83a047-5686-4f9a-c4ff-b8c5c9576ca6"
      },
      "source": [
        "# Using the likelihoods computed from the bigram classiffer, and starting with a seed word \"alice\", \n",
        "# generate the next 25 words by always picking the most likely next word.\n",
        "word = \"alice\"\n",
        "article = word\n",
        "for i in range(25):\n",
        "    word, _ = pred_2gram(word)\n",
        "    article = article + \" \" + word\n",
        "print(article)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice was a little thing i can remember ever saw in a little thing i can remember ever saw in a little thing i can remember\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvHOJOuAh1pi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5776f1f1-bcf0-429e-d6e4-e389e9fcfd21"
      },
      "source": [
        "# Using random choices method\n",
        "word = \"alice\"\n",
        "article = word\n",
        "for i in range(25):\n",
        "    likelihood = get_likelihood_2gram(word)\n",
        "    word = random.choices(dictionary, weights = likelihood)[0]\n",
        "    article = article + \" \" + word\n",
        "print(article)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice hastily your head uncomfortable the mouse sharply advise you couldn have grown woman and she could not notice this elegant thimble looking at each side\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCZznhTxfipB",
        "outputId": "d406c337-ec7b-4d94-9312-ac65ac2f6666"
      },
      "source": [
        "# Calculate the acc of 1 word.\n",
        "positive = 0\n",
        "for i in range(len(corpus) - 1):\n",
        "    if pred_2gram(corpus[i])[0] == corpus[i+1]:\n",
        "        positive += 1\n",
        "print(\"The accuracy:\", positive / (len(corpus)-1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy: 0.2453493423910897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHz0xgu5fkJE",
        "outputId": "db6f43db-af5d-41ea-da83-a1a95f9c6276"
      },
      "source": [
        "#past 2 words as features\n",
        "\n",
        "posterior_2words = np.zeros((V, V))\n",
        "for i in range(0, len(corpus) - 2):\n",
        "    posterior_2words[tokenize[corpus[i]]][tokenize[corpus[i + 2]]] += 1 \n",
        "posterior_2words /= prior\n",
        "\n",
        "posterior_2gram = np.vstack([posterior_1word,posterior_2words])\n",
        "\n",
        "\n",
        "\n",
        "def get_likelihood_3gram(word2ago,word1ago):\n",
        "    likelihood = posterior_1word[tokenize[word1ago], :] * posterior_2words[tokenize[word2ago], :] * prior\n",
        "    return likelihood\n",
        "def pred_3gram(word2ago,word1ago):\n",
        "    likelihood = get_likelihood_3gram(word2ago,word1ago)\n",
        "    i = np.argmax(likelihood)\n",
        "    return dictionary[i], likelihood[i]\n",
        "print(pred_3gram('pack','of'))\n",
        "print(pred_3gram('the','mad'))\n",
        "print(pred_3gram('she','jumped'))\n",
        "\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('cards', 3.0)\n",
            "('you', 0.14447592067988668)\n",
            "('up', 0.5416666666666666)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXhdIFPuflrU",
        "outputId": "4b81329c-394f-4545-d6a3-8d9826c24dfe"
      },
      "source": [
        "first_word = \"alice\"\n",
        "second_word = \"was\"\n",
        "article = first_word + \" \" + second_word\n",
        "for i in range(25):\n",
        "    new, _ = pred_3gram(first_word, second_word)\n",
        "    article = article + \" \" + new\n",
        "    first_word = second_word\n",
        "    second_word = new\n",
        "print(article)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice was not easy to take this young lady tells us a story afraid i am i ah that the queen who was peeping anxiously into its\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUS1B2okfnFb",
        "outputId": "58ef9ad6-30c9-4ac4-f450-452605c224ed"
      },
      "source": [
        "# Using random choices method\n",
        "first_word = \"alice\"\n",
        "second_word = \"was\"\n",
        "article = first_word + \" \" + second_word\n",
        "for i in range(25):\n",
        "    likelihood = get_likelihood_3gram(first_word, second_word)\n",
        "    new = random.choices(dictionary, weights = likelihood)[0]\n",
        "    article = article + \" \" + new\n",
        "    first_word = second_word\n",
        "    second_word = new\n",
        "print(article)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice was not like mad tea chapter viii the queen smiled and passed by his garden and she had caught the baby joined wow wow while the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml8FTUs7fohP",
        "outputId": "078f25d6-8902-448c-fbc3-9944b00ce159"
      },
      "source": [
        "# Calculate the acc of 2 word.\n",
        "positive = 0\n",
        "for i in range(len(corpus) - 2):\n",
        "    if pred_3gram(corpus[i], corpus[i + 1])[0] == corpus[i+2]:\n",
        "        positive += 1\n",
        "print(\"The accuracy:\", positive / (len(corpus)-2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy: 0.5047397108776365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC9gPyT2ItXd"
      },
      "source": [
        "# Challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikTXQi1aIvsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194536a7-c34c-4495-be94-12132de90901"
      },
      "source": [
        "test_corpus = []\n",
        "f = open('through_the_looking_glass.txt','r')\n",
        "while(1):\n",
        "    line =  f.readline()\n",
        "    if len(line) == 0: break\n",
        "    test_corpus.extend(line.split())\n",
        "        \n",
        "f.close()\n",
        "test_corpus = ' '.join(test_corpus)\n",
        "\n",
        "test_corpus = [clean_word(word) for word in test_corpus.split()]\n",
        "new_corpus = []\n",
        "for word in test_corpus:\n",
        "    if len(word) > 0 and word in dictionary:\n",
        "        new_corpus.append(word)\n",
        "test_corpus = new_corpus\n",
        "print(test_corpus[:25])\n",
        "test_D = len(test_corpus)\n",
        "print('test corpus len: ',test_D)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['through', 'the', 'looking', 'and', 'what', 'alice', 'found', 'there', 'by', 'lewis', 'carroll', 'child', 'of', 'the', 'and', 'dreaming', 'eyes', 'of', 'wonder', 'though', 'time', 'be', 'and', 'i', 'and']\n",
            "test corpus len:  24823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kso6leoLIx3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4172b92-ded6-4145-a60f-f9c5676c75ac"
      },
      "source": [
        "test_tokenize = {}\n",
        "test_dictionary = []\n",
        "test_token = 0\n",
        "for word in test_corpus:\n",
        "    if word not in test_tokenize.keys():\n",
        "        test_tokenize[word] = token\n",
        "        test_dictionary.append(word)\n",
        "        test_token += 1\n",
        "\n",
        "test_V = len(test_dictionary)\n",
        "print('test dictionary size (number of distinct words): ', test_V)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test dictionary size (number of distinct words):  1470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bTsWXltIydA"
      },
      "source": [
        "posterior_n_words = []\n",
        "for i in range(1, 101):\n",
        "    posterior_i_words = np.zeros((V, V))\n",
        "    for j in range(0, len(corpus) - i):\n",
        "        posterior_i_words[tokenize[corpus[j]]][tokenize[corpus[j + i]]] += 1 \n",
        "    posterior_i_words /= prior\n",
        "    posterior_n_words.append(posterior_i_words)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDl7pKJCI1cR"
      },
      "source": [
        "def get_likelihood_n_gram(word_n_agos):\n",
        "    n = len(word_n_agos)\n",
        "    likelihood = 1\n",
        "    for i in range(n):\n",
        "        likelihood *= posterior_n_words[i][tokenize[word_n_agos[i]], :]\n",
        "    likelihood *= prior\n",
        "    return likelihood\n",
        "def pred_n_gram(word_n_agos):\n",
        "    likelihood = get_likelihood_n_gram(word_n_agos)\n",
        "    i = np.argmax(likelihood)\n",
        "    return dictionary[i], likelihood[i]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2fSApq17bwg",
        "outputId": "c2364ee2-c932-4b3d-a39b-708110e02763"
      },
      "source": [
        "# Calculate the acc of n word.\n",
        "n_gram = 100\n",
        "positive = 0\n",
        "for i in range(len(corpus) - n_gram):\n",
        "    if pred_n_gram(corpus[i:i+n_gram][::-1])[0] == corpus[i+n_gram]:\n",
        "        positive += 1\n",
        "print(\"The accuracy:\", positive / (len(corpus) - n_gram))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in multiply\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWg0DqxI7eWB"
      },
      "source": [
        "Training accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDa9vO677fam",
        "outputId": "6a5c6b2d-4bc9-46c3-a8fd-376c3ac18278"
      },
      "source": [
        "for n_gram in range(1, 101):\n",
        "    positive = 0\n",
        "    for i in range(len(corpus) - n_gram):\n",
        "        if pred_n_gram(corpus[i:i+n_gram][::-1])[0] == corpus[i+n_gram]:\n",
        "            positive += 1\n",
        "    print(\"n_gram = \", n_gram, \" The accuracy:\", positive / (len(corpus) - n_gram))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram =  1  The accuracy: 0.2453493423910897\n",
            "n_gram =  2  The accuracy: 0.5047002132869894\n",
            "n_gram =  3  The accuracy: 0.7499703756369238\n",
            "n_gram =  4  The accuracy: 0.8784563122136199\n",
            "n_gram =  5  The accuracy: 0.9401935611297649\n",
            "n_gram =  6  The accuracy: 0.9667772773959074\n",
            "n_gram =  7  The accuracy: 0.9831311974084462\n",
            "n_gram =  8  The accuracy: 0.9897281921618205\n",
            "n_gram =  9  The accuracy: 0.9937971632886887\n",
            "n_gram =  10  The accuracy: 0.9960489924930858\n",
            "n_gram =  11  The accuracy: 0.997313208739974\n",
            "n_gram =  12  The accuracy: 0.9983404457088667\n",
            "n_gram =  13  The accuracy: 0.9988935867546529\n",
            "n_gram =  14  The accuracy: 0.9991701572749545\n",
            "n_gram =  15  The accuracy: 0.999407231772377\n",
            "n_gram =  16  The accuracy: 0.9995652861207714\n",
            "n_gram =  17  The accuracy: 0.9996443109512706\n",
            "n_gram =  18  The accuracy: 0.9996442968935262\n",
            "n_gram =  19  The accuracy: 0.9998023793525948\n",
            "n_gram =  20  The accuracy: 0.9998418972332016\n",
            "n_gram =  21  The accuracy: 0.9999209454919167\n",
            "n_gram =  22  The accuracy: 0.9999604711834927\n",
            "n_gram =  23  The accuracy: 0.9999604696209037\n",
            "n_gram =  24  The accuracy: 0.999960468058191\n",
            "n_gram =  25  The accuracy: 0.9999604664953549\n",
            "n_gram =  26  The accuracy: 0.999960464932395\n",
            "n_gram =  27  The accuracy: 0.9999604633693117\n",
            "n_gram =  28  The accuracy: 0.9999604618061047\n",
            "n_gram =  29  The accuracy: 0.9999604602427741\n",
            "n_gram =  30  The accuracy: 0.9999604586793199\n",
            "n_gram =  31  The accuracy: 0.999960457115742\n",
            "n_gram =  32  The accuracy: 1.0\n",
            "n_gram =  33  The accuracy: 1.0\n",
            "n_gram =  34  The accuracy: 1.0\n",
            "n_gram =  35  The accuracy: 1.0\n",
            "n_gram =  36  The accuracy: 1.0\n",
            "n_gram =  37  The accuracy: 1.0\n",
            "n_gram =  38  The accuracy: 1.0\n",
            "n_gram =  39  The accuracy: 1.0\n",
            "n_gram =  40  The accuracy: 1.0\n",
            "n_gram =  41  The accuracy: 1.0\n",
            "n_gram =  42  The accuracy: 1.0\n",
            "n_gram =  43  The accuracy: 1.0\n",
            "n_gram =  44  The accuracy: 1.0\n",
            "n_gram =  45  The accuracy: 1.0\n",
            "n_gram =  46  The accuracy: 1.0\n",
            "n_gram =  47  The accuracy: 1.0\n",
            "n_gram =  48  The accuracy: 1.0\n",
            "n_gram =  49  The accuracy: 1.0\n",
            "n_gram =  50  The accuracy: 1.0\n",
            "n_gram =  51  The accuracy: 1.0\n",
            "n_gram =  52  The accuracy: 1.0\n",
            "n_gram =  53  The accuracy: 1.0\n",
            "n_gram =  54  The accuracy: 1.0\n",
            "n_gram =  55  The accuracy: 1.0\n",
            "n_gram =  56  The accuracy: 1.0\n",
            "n_gram =  57  The accuracy: 1.0\n",
            "n_gram =  58  The accuracy: 1.0\n",
            "n_gram =  59  The accuracy: 1.0\n",
            "n_gram =  60  The accuracy: 1.0\n",
            "n_gram =  61  The accuracy: 1.0\n",
            "n_gram =  62  The accuracy: 1.0\n",
            "n_gram =  63  The accuracy: 1.0\n",
            "n_gram =  64  The accuracy: 1.0\n",
            "n_gram =  65  The accuracy: 1.0\n",
            "n_gram =  66  The accuracy: 1.0\n",
            "n_gram =  67  The accuracy: 1.0\n",
            "n_gram =  68  The accuracy: 1.0\n",
            "n_gram =  69  The accuracy: 1.0\n",
            "n_gram =  70  The accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in multiply\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram =  71  The accuracy: 1.0\n",
            "n_gram =  72  The accuracy: 1.0\n",
            "n_gram =  73  The accuracy: 1.0\n",
            "n_gram =  74  The accuracy: 1.0\n",
            "n_gram =  75  The accuracy: 1.0\n",
            "n_gram =  76  The accuracy: 1.0\n",
            "n_gram =  77  The accuracy: 1.0\n",
            "n_gram =  78  The accuracy: 1.0\n",
            "n_gram =  79  The accuracy: 1.0\n",
            "n_gram =  80  The accuracy: 1.0\n",
            "n_gram =  81  The accuracy: 1.0\n",
            "n_gram =  82  The accuracy: 1.0\n",
            "n_gram =  83  The accuracy: 1.0\n",
            "n_gram =  84  The accuracy: 1.0\n",
            "n_gram =  85  The accuracy: 1.0\n",
            "n_gram =  86  The accuracy: 1.0\n",
            "n_gram =  87  The accuracy: 1.0\n",
            "n_gram =  88  The accuracy: 1.0\n",
            "n_gram =  89  The accuracy: 1.0\n",
            "n_gram =  90  The accuracy: 1.0\n",
            "n_gram =  91  The accuracy: 1.0\n",
            "n_gram =  92  The accuracy: 1.0\n",
            "n_gram =  93  The accuracy: 1.0\n",
            "n_gram =  94  The accuracy: 1.0\n",
            "n_gram =  95  The accuracy: 1.0\n",
            "n_gram =  96  The accuracy: 1.0\n",
            "n_gram =  97  The accuracy: 1.0\n",
            "n_gram =  98  The accuracy: 1.0\n",
            "n_gram =  99  The accuracy: 1.0\n",
            "n_gram =  100  The accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG_TbZky7jAH"
      },
      "source": [
        "Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqXDDNnZ7lG6",
        "outputId": "66a0b8f5-17b6-4f39-ec65-846e500a409b"
      },
      "source": [
        "for n_gram in range(1, 101):\n",
        "    positive = 0\n",
        "    for i in range(len(test_corpus) - n_gram):\n",
        "        if pred_n_gram(test_corpus[i:i+n_gram][::-1])[0] == test_corpus[i+n_gram]:\n",
        "            positive += 1\n",
        "    print(\"n_gram = \", n_gram, \" The test accuracy:\", positive / (len(test_corpus) - n_gram))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram =  1  The test accuracy: 0.12730642172266537\n",
            "n_gram =  2  The test accuracy: 0.09085048950485476\n",
            "n_gram =  3  The test accuracy: 0.07626913779210315\n",
            "n_gram =  4  The test accuracy: 0.06269390386397518\n",
            "n_gram =  5  The test accuracy: 0.05230074945603997\n",
            "n_gram =  6  The test accuracy: 0.043921505419672\n",
            "n_gram =  7  The test accuracy: 0.037757898130238554\n",
            "n_gram =  8  The test accuracy: 0.03256095103767882\n",
            "n_gram =  9  The test accuracy: 0.029580075763681792\n",
            "n_gram =  10  The test accuracy: 0.02684076895175916\n",
            "n_gram =  11  The test accuracy: 0.025270030630340157\n",
            "n_gram =  12  The test accuracy: 0.023981298617548667\n",
            "n_gram =  13  The test accuracy: 0.022934300685207576\n",
            "n_gram =  14  The test accuracy: 0.022048450159216415\n",
            "n_gram =  15  The test accuracy: 0.021122218639148663\n",
            "n_gram =  16  The test accuracy: 0.020316846051517717\n",
            "n_gram =  17  The test accuracy: 0.019592034185277756\n",
            "n_gram =  18  The test accuracy: 0.019068736141906874\n",
            "n_gram =  19  The test accuracy: 0.018505079825834544\n",
            "n_gram =  20  The test accuracy: 0.01806233116961658\n",
            "n_gram =  21  The test accuracy: 0.017982420772518347\n",
            "n_gram =  22  The test accuracy: 0.017942824886093302\n",
            "n_gram =  23  The test accuracy: 0.017862903225806453\n",
            "n_gram =  24  The test accuracy: 0.01782329932658575\n",
            "n_gram =  25  The test accuracy: 0.017743366400516172\n",
            "n_gram =  26  The test accuracy: 0.017663427027463\n",
            "n_gram =  27  The test accuracy: 0.017623810291982577\n",
            "n_gram =  28  The test accuracy: 0.017584190360959873\n",
            "n_gram =  29  The test accuracy: 0.01738323788013229\n",
            "n_gram =  30  The test accuracy: 0.017303271084580324\n",
            "n_gram =  31  The test accuracy: 0.017263633430138755\n",
            "n_gram =  32  The test accuracy: 0.017223992577951677\n",
            "n_gram =  33  The test accuracy: 0.017224687373941106\n",
            "n_gram =  34  The test accuracy: 0.017225382225987334\n",
            "n_gram =  35  The test accuracy: 0.017226077134097142\n",
            "n_gram =  36  The test accuracy: 0.01722677209827732\n",
            "n_gram =  37  The test accuracy: 0.017267812474784153\n",
            "n_gram =  38  The test accuracy: 0.017268509178938875\n",
            "n_gram =  39  The test accuracy: 0.017269205939315687\n",
            "n_gram =  40  The test accuracy: 0.0172699027559214\n",
            "n_gram =  41  The test accuracy: 0.01727059962876281\n",
            "n_gram =  42  The test accuracy: 0.017271296557846736\n",
            "n_gram =  43  The test accuracy: 0.017271993543179983\n",
            "n_gram =  44  The test accuracy: 0.017232333831066628\n",
            "n_gram =  45  The test accuracy: 0.017192670917749616\n",
            "n_gram =  46  The test accuracy: 0.01719336481414215\n",
            "n_gram =  47  The test accuracy: 0.01719405876654827\n",
            "n_gram =  48  The test accuracy: 0.017194752774974773\n",
            "n_gram =  49  The test accuracy: 0.017195446839428433\n",
            "n_gram =  50  The test accuracy: 0.017196140959916038\n",
            "n_gram =  51  The test accuracy: 0.017196835136444374\n",
            "n_gram =  52  The test accuracy: 0.017197529369020224\n",
            "n_gram =  53  The test accuracy: 0.017198223657650384\n",
            "n_gram =  54  The test accuracy: 0.017198918002341638\n",
            "n_gram =  55  The test accuracy: 0.017199612403100775\n",
            "n_gram =  56  The test accuracy: 0.01720030685993459\n",
            "n_gram =  57  The test accuracy: 0.017201001372849876\n",
            "n_gram =  58  The test accuracy: 0.01720169594185342\n",
            "n_gram =  59  The test accuracy: 0.01720239056695203\n",
            "n_gram =  60  The test accuracy: 0.017203085248152485\n",
            "n_gram =  61  The test accuracy: 0.017203779985461593\n",
            "n_gram =  62  The test accuracy: 0.01720447477888615\n",
            "n_gram =  63  The test accuracy: 0.017205169628432958\n",
            "n_gram =  64  The test accuracy: 0.01720586453410881\n",
            "n_gram =  65  The test accuracy: 0.01720655949592051\n",
            "n_gram =  66  The test accuracy: 0.017207254513874864\n",
            "n_gram =  67  The test accuracy: 0.017207949587978673\n",
            "n_gram =  68  The test accuracy: 0.017208644718238738\n",
            "n_gram =  69  The test accuracy: 0.017209339904661874\n",
            "n_gram =  70  The test accuracy: 0.017210035147254877\n",
            "n_gram =  71  The test accuracy: 0.017210730446024565\n",
            "n_gram =  72  The test accuracy: 0.017211425800977738\n",
            "n_gram =  73  The test accuracy: 0.017212121212121213\n",
            "n_gram =  74  The test accuracy: 0.017212816679461798\n",
            "n_gram =  75  The test accuracy: 0.017213512203006303\n",
            "n_gram =  76  The test accuracy: 0.017214207782761545\n",
            "n_gram =  77  The test accuracy: 0.017214903418734342\n",
            "n_gram =  78  The test accuracy: 0.0172155991109315\n",
            "n_gram =  79  The test accuracy: 0.017216294859359844\n",
            "n_gram =  80  The test accuracy: 0.01721699066402619\n",
            "n_gram =  81  The test accuracy: 0.017217686524937353\n",
            "n_gram =  82  The test accuracy: 0.017218382442100156\n",
            "n_gram =  83  The test accuracy: 0.01721907841552142\n",
            "n_gram =  84  The test accuracy: 0.01721977444520797\n",
            "n_gram =  85  The test accuracy: 0.017220470531166626\n",
            "n_gram =  86  The test accuracy: 0.017221166673404214\n",
            "n_gram =  87  The test accuracy: 0.017221862871927555\n",
            "n_gram =  88  The test accuracy: 0.017222559126743482\n",
            "n_gram =  89  The test accuracy: 0.01722325543785882\n",
            "n_gram =  90  The test accuracy: 0.017223951805280396\n",
            "n_gram =  91  The test accuracy: 0.01722464822901504\n",
            "n_gram =  92  The test accuracy: 0.017225344709069588\n",
            "n_gram =  93  The test accuracy: 0.01722604124545087\n",
            "n_gram =  94  The test accuracy: 0.017226737838165716\n",
            "n_gram =  95  The test accuracy: 0.017227434487220965\n",
            "n_gram =  96  The test accuracy: 0.01722813119262345\n",
            "n_gram =  97  The test accuracy: 0.017228827954380004\n",
            "n_gram =  98  The test accuracy: 0.017229524772497472\n",
            "n_gram =  99  The test accuracy: 0.01723022164698269\n",
            "n_gram =  100  The test accuracy: 0.017230918577842494\n"
          ]
        }
      ]
    }
  ]
}