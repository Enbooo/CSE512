{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "alice_nlp_release_EnboYu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEJkuUgGlixN"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgScl5MqlnBn",
        "outputId": "a235eeec-b586-4bcc-9ec8-c5186d470262"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehxZCLkBltV-"
      },
      "source": [
        "import os\n",
        "code_path = \"/content/gdrive/MyDrive/cse512hw5/alice_release_new/\"\n",
        "os.chdir(code_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "7njZTGOWlixS",
        "outputId": "cf19dc18-2f61-4c25-e545-4c64768ae1e2"
      },
      "source": [
        "#This was the process used to load and clean the corpus, and produce the corrupted corpus.\n",
        "#You don't need to do anything here.\n",
        "\"\"\"\n",
        "corpus = []\n",
        "f = open('alice_in_wonderland.txt','r')\n",
        "while(1):\n",
        "    line =  f.readline()\n",
        "    if len(line) == 0: break\n",
        "    corpus.extend(line.split())\n",
        "        \n",
        "f.close()\n",
        "\n",
        "\n",
        "def clean_word(word):\n",
        "    word = word.lower().strip()\n",
        "    for punctuation in ['*','\"',\"'\",'.',',','-','?','!',';',':','—','(',')','[',']']:\n",
        "        \n",
        "        word = ''.join(word.split(punctuation))\n",
        "    \n",
        "    return word\n",
        "\n",
        "corpus = [clean_word(word) for word in corpus]\n",
        "corpus = [word for word in corpus if len(word) > 0]\n",
        "\n",
        "corrupted_corpus = copy.deepcopy(corpus)\n",
        "\n",
        "p = .25\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "for k in xrange(len(corrupted_corpus)):\n",
        "    word = corrupted_corpus[k]\n",
        "    if len(word) < 2: continue\n",
        "    if np.random.rand() < p:\n",
        "        if np.random.randn() < 0:\n",
        "            swap = np.random.choice(range(len(word)), size=2, replace = False)\n",
        "            swap = np.sort(swap)\n",
        "            word = ''.join([word[:swap[0]], word[swap[1]], word[swap[0]+1:swap[1]], word[swap[0]], word[swap[1]+1:]])\n",
        "        else:\n",
        "            \n",
        "            replace = np.random.choice(range(len(word)), size=1, replace = False)[0]\n",
        "            replace_with = alphabet[np.random.choice(range(len(alphabet)),size=1)[0]]\n",
        "            word = ''.join([word[:replace], replace_with, word[replace+1:]])\n",
        "        \n",
        "        corrupted_corpus[k] = word\n",
        "\n",
        "pickle.dump({'corpus':corpus,'corrupted_corpus':corrupted_corpus},open('alice_spelling.pkl','wb'))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ncorpus = []\\nf = open(\\'alice_in_wonderland.txt\\',\\'r\\')\\nwhile(1):\\n    line =  f.readline()\\n    if len(line) == 0: break\\n    corpus.extend(line.split())\\n        \\nf.close()\\n\\n\\ndef clean_word(word):\\n    word = word.lower().strip()\\n    for punctuation in [\\'*\\',\\'\"\\',\"\\'\",\\'.\\',\\',\\',\\'-\\',\\'?\\',\\'!\\',\\';\\',\\':\\',\\'—\\',\\'(\\',\\')\\',\\'[\\',\\']\\']:\\n        \\n        word = \\'\\'.join(word.split(punctuation))\\n    \\n    return word\\n\\ncorpus = [clean_word(word) for word in corpus]\\ncorpus = [word for word in corpus if len(word) > 0]\\n\\ncorrupted_corpus = copy.deepcopy(corpus)\\n\\np = .25\\nalphabet = \\'abcdefghijklmnopqrstuvwxyz\\'\\nfor k in xrange(len(corrupted_corpus)):\\n    word = corrupted_corpus[k]\\n    if len(word) < 2: continue\\n    if np.random.rand() < p:\\n        if np.random.randn() < 0:\\n            swap = np.random.choice(range(len(word)), size=2, replace = False)\\n            swap = np.sort(swap)\\n            word = \\'\\'.join([word[:swap[0]], word[swap[1]], word[swap[0]+1:swap[1]], word[swap[0]], word[swap[1]+1:]])\\n        else:\\n            \\n            replace = np.random.choice(range(len(word)), size=1, replace = False)[0]\\n            replace_with = alphabet[np.random.choice(range(len(alphabet)),size=1)[0]]\\n            word = \\'\\'.join([word[:replace], replace_with, word[replace+1:]])\\n        \\n        corrupted_corpus[k] = word\\n\\npickle.dump({\\'corpus\\':corpus,\\'corrupted_corpus\\':corrupted_corpus},open(\\'alice_spelling.pkl\\',\\'wb\\'))\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_HBa5J5lixU",
        "outputId": "1aedb466-fa02-4acf-c8d9-d9c8b3031651"
      },
      "source": [
        "#Take a look at how the data looks, and let's make some helper functions.\n",
        "data = pickle.load(open('alice_spelling.pkl','rb'), encoding='utf-8')\n",
        "vocab = np.unique(data['corpus'])\n",
        "V = len(vocab)\n",
        "print(V)\n",
        "\n",
        "## CORRECT VS INCORRECT CORPUS\n",
        "##For now, we will hold onto both the correct and incorrect corpuses. Later, you will only process the incorrect corpus, and the correct corpus is only used as a reference to check for recovery accuracy.\n",
        "def recovery_rate(new_corpus, correct_corpus):\n",
        "    wrong = 0\n",
        "    for k in range(len(new_corpus)):\n",
        "        if new_corpus[k] != correct_corpus[k]:\n",
        "            wrong += 1\n",
        "    return 1.- wrong/(len(new_corpus)+0.)\n",
        "print('current recovery rate', recovery_rate(data['corpus'],data['corrupted_corpus']))\n",
        "\n",
        "## Probability of a word mispelling\n",
        "## We will use the following function to predict whether a misspelled word was actually another word. To avoid numerical issues, we make sure that the probablity is always something nonzero.\n",
        "def prob_correct(word1,word2):\n",
        "    SMALLNUM = 0.000001 \n",
        "    if len(word1) != len(word2): return SMALLNUM\n",
        "    num_wrong = np.sum(np.array([word1[k] == word2[k] for k in range(len(word1))]))\n",
        "    return np.maximum(num_wrong / (len(word1) + 0.),SMALLNUM)\n",
        "\n",
        "print ('prob not misspelling alice vs alace', prob_correct('alice','alace'))\n",
        "print ('prob not misspelling alice vs earth', prob_correct('alice','earth'))\n",
        "print ('prob not misspelling machinelearning vs machinedreaming', prob_correct('machinelearning','machinedreaming'))\n",
        "print ('prob not misspelling machinelearning vs artificalintell', prob_correct('machinelearning','artificalintell'))\n",
        "\n",
        "##HASHING\n",
        "#all of our objects should be vectors of length V or matrices which are V x V. \n",
        "#the kth word in the vocab list is represented by the kth element of the vector, and the relationship between the i,jth words is represented in the i,jth element in the matrix.\n",
        "# to easily go between the word indices and words themselves, we need to make a hash table. \n",
        "vocab_hash = {}\n",
        "for k in range(len(vocab)):\n",
        "    vocab_hash[vocab[k]] = k\n",
        "    \n",
        "#now, to access the $k$th word, we do vocab[k]. To access the index of a word, we call vocab_hash[word].\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2759\n",
            "current recovery rate 0.7716434266712013\n",
            "prob not misspelling alice vs alace 0.8\n",
            "prob not misspelling alice vs earth 1e-06\n",
            "prob not misspelling machinelearning vs machinedreaming 0.6666666666666666\n",
            "prob not misspelling machinelearning vs artificalintell 1e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww5ewpiQlixX",
        "outputId": "506e1cbb-4fa1-403a-940d-1c8f05329138"
      },
      "source": [
        "## FILL ME IN ##\n",
        "\n",
        "#WORD FREQUENCY\n",
        "#create an array of length V where V[k] returns the normalized frequency of word k in the entire data corpus. Do so by filling in this function.\n",
        "def get_word_prob(corpus):\n",
        "    vocab = np.unique(corpus)\n",
        "    length = len(vocab)\n",
        "    word_prob = np.zeros(length)\n",
        "    frequency = Counter(corpus)\n",
        "    for i,key in enumerate(vocab):\n",
        "        word_prob[i] =  frequency[key]/(len(corpus) + 0.)\n",
        "    \n",
        "    return word_prob\n",
        " \n",
        "word_prob =  get_word_prob(data['corpus'])\n",
        "\n",
        "#report the answer of the following:\n",
        "print ('prob. of \"alice\"', word_prob[vocab_hash['alice']])\n",
        "print ('prob. of \"queen\"', word_prob[vocab_hash['queen']])\n",
        "print ('prob. of \"chapter\"', word_prob[vocab_hash['chapter']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob. of \"alice\" 0.014548615047424706\n",
            "prob. of \"queen\" 0.002569625514869818\n",
            "prob. of \"chapter\" 0.0009069266523069947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar2Jye33qVo2"
      },
      "source": [
        "# No Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhKKAwRxqU9X",
        "outputId": "88e7de12-741e-4608-af20-2c05043846c4"
      },
      "source": [
        "# Pr(word | prev word) \n",
        "# Using the uncorrupted corpus, accumulate the conditional transition probabilities. Do so via this formula:\n",
        "# pr(word | prev) = max(# times 'prev' preceded 'word' , 1) / # times prev appears\n",
        "# where again, we ensure that this number is never 0 with some small smoothing.\n",
        "def get_transition_matrix(corpus):\n",
        "    SMALLNUM = 0.000001 \n",
        "    vocab = np.unique(corpus)\n",
        "    length = len(corpus)\n",
        "    # transition_matrix = np.ones((len(vocab),len(vocab)))*SMALLNUM \n",
        "    transition_matrix = np.zeros((len(vocab),len(vocab)))\n",
        "    for key in range(length-1):\n",
        "        i = vocab_hash[corpus[key]]\n",
        "        j = vocab_hash[corpus[key+1]]\n",
        "        transition_matrix[j, i] = transition_matrix[j, i] + 1  # note key+1 is the original word\n",
        "\n",
        "    for i in range(len(vocab)):\n",
        "        transition_matrix[:, i] = transition_matrix[:, i] / corpus.count(vocab[i])\n",
        "\n",
        "    return transition_matrix\n",
        "\n",
        "transition_matrix = get_transition_matrix(data['corpus'])\n",
        "print ('prob. of \"the alice\"', transition_matrix[vocab_hash['alice'],vocab_hash['the']])\n",
        "print ('prob. of \"the queen\"', transition_matrix[vocab_hash['queen'],vocab_hash['the']])\n",
        "print ('prob. of \"the chapter\"', transition_matrix[vocab_hash['chapter'],vocab_hash['the']])\n",
        "print ('prob. of \"the hatter\"\"', transition_matrix[vocab_hash['hatter'],vocab_hash['the']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob. of \"the alice\" 0.0\n",
            "prob. of \"the queen\" 0.03968253968253968\n",
            "prob. of \"the chapter\" 0.0\n",
            "prob. of \"the hatter\"\" 0.031135531135531136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRYkFm2jlixZ",
        "outputId": "06da0ded-635d-448c-c2a2-b2bf6a19467f"
      },
      "source": [
        "# The prior probabilities are just the word frequencies\n",
        "prior = word_prob  + 0.\n",
        "\n",
        "# Write a function that returns the emission probability of a potentially misspelled word, by comparing its probabilities against every word in the correct vocabulary\n",
        "\n",
        "def get_emission(mword):\n",
        "    return np.zeros(V)\n",
        "\n",
        "def get_prob():\n",
        "    prob = np.zeros(V)\n",
        "    for i in range(V):\n",
        "        prob[i] = prob_correct(mword, vocab[i])\n",
        "    return prob\n",
        "\n",
        "#find the 10 closest words to 'abice' and report them\n",
        "idx = np.argsort(get_emission('abice'))[::-1]\n",
        "print([vocab[j] for j in idx[:10]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abide', 'alice', 'above', 'voice', 'alive', 'twice', 'thick', 'dance', 'stick', 'prize']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eX5nFBolixZ"
      },
      "source": [
        "#now we reduce our attention to a small segment of the corrupted corpus\n",
        "corrupt_corpus =   data['corrupted_corpus'][:1000]\n",
        "correct_corpus =   data['corpus'][:1000]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH0X-4Awz8H2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ardp-d5Alixa",
        "outputId": "29a55e76-b054-4352-bf90-f71e6383b9e1"
      },
      "source": [
        "# encode the HMM spelling corrector. To debug, you can see the first hundred words of both the corrupted and proposed corpus, to see if spelling words got corrupted.\n",
        "\n",
        "# report the recovery rate of the proposed (corrected) corpus.\n",
        "\n",
        "\n",
        "# Forward Step\n",
        "forward_probs = np.ones((len(corrupt_corpus), V))/(V+0.)\n",
        "\n",
        "emission_mat = get_emission(corrupt_corpus[0])\n",
        "\n",
        "for i in range(V): \n",
        "    forward_probs[0, i] = emission_mat[i]*word_prob[i]\n",
        "\n",
        "for j in range(len(corrupt_corpus)-1):\n",
        "\n",
        "    emission_pb = get_emission(corrupt_corpus[j+1])\n",
        "\n",
        "    for i in range(V):\n",
        "            trans = transition_matrix[i, :]\n",
        "\n",
        "            emssion = emission_pb[i]\n",
        "            forward_probs[j + 1, i] = emssion * np.sum(trans * forward_probs[j, :])\n",
        "\n",
        "    forward_probs[j + 1, :] = forward_probs[j+1, :]/np.sum(forward_probs[j + 1, :])\n",
        "\n",
        "# Backward Step\n",
        "backward_probs = np.ones((len(corrupt_corpus), V))/(V+0.)\n",
        "\n",
        "for i in range(len(corrupt_corpus))[::-1]:\n",
        "    if i == len(corrupt_corpus) - 1:\n",
        "        for j in range(V):\n",
        "            backward_probs[i, j] = 1.\n",
        "\n",
        "    else:\n",
        "        emission_mat = get_emission(corrupt_corpus[i + 1])\n",
        "        for j in range(V):\n",
        "            trans = transition_matrix[:, j].T\n",
        "\n",
        "            backward_probs[i, j] = np.sum(emission_mat * trans * backward_probs[i+1, :])\n",
        "\n",
        "    backward_probs[i, :] = backward_probs[i, :]/np.sum(backward_probs[i, :])\n",
        "\n",
        "\n",
        "# compute corrected corpus\n",
        "proposed_corpus = copy.deepcopy(corrupt_corpus)\n",
        "\n",
        "for i in range(len(proposed_corpus)):\n",
        "    prob_z = forward_probs[i, :] * backward_probs[i, :]\n",
        "    proposed_corpus[i] = vocab[np.argmax(prob_z)]\n",
        "\n",
        "for j in range(100):\n",
        "    print(proposed_corpus[j], corrupt_corpus[j])\n",
        "    print('Correct world: ' + correct_corpus[j])\n",
        "\n",
        "print(recovery_rate(corrupt_corpus, correct_corpus), recovery_rate(proposed_corpus, correct_corpus))\n",
        "\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alices alices\n",
            "Correct world:alices\n",
            "adventures adventures\n",
            "Correct world:adventures\n",
            "in in\n",
            "Correct world:in\n",
            "wonderland wonderland\n",
            "Correct world:wonderland\n",
            "by yb\n",
            "Correct world:by\n",
            "lewis lewia\n",
            "Correct world:lewis\n",
            "carroll carroll\n",
            "Correct world:carroll\n",
            "the the\n",
            "Correct world:the\n",
            "millennium millennium\n",
            "Correct world:millennium\n",
            "fulcrum fulcrkm\n",
            "Correct world:fulcrum\n",
            "edition edition\n",
            "Correct world:edition\n",
            "30 30\n",
            "Correct world:30\n",
            "contents contents\n",
            "Correct world:contents\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "i i\n",
            "Correct world:i\n",
            "dont down\n",
            "Correct world:down\n",
            "the tqe\n",
            "Correct world:the\n",
            "rabbithole raibbthole\n",
            "Correct world:rabbithole\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "ii ii\n",
            "Correct world:ii\n",
            "the the\n",
            "Correct world:the\n",
            "pool pooo\n",
            "Correct world:pool\n",
            "of of\n",
            "Correct world:of\n",
            "tears aetrs\n",
            "Correct world:tears\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "iii dii\n",
            "Correct world:iii\n",
            "a a\n",
            "Correct world:a\n",
            "caucusrace caucusrace\n",
            "Correct world:caucusrace\n",
            "and and\n",
            "Correct world:and\n",
            "a a\n",
            "Correct world:a\n",
            "long long\n",
            "Correct world:long\n",
            "tale tael\n",
            "Correct world:tale\n",
            "chapter yhapter\n",
            "Correct world:chapter\n",
            "iv iv\n",
            "Correct world:iv\n",
            "the the\n",
            "Correct world:the\n",
            "rabbit raibbt\n",
            "Correct world:rabbit\n",
            "sends sends\n",
            "Correct world:sends\n",
            "in ni\n",
            "Correct world:in\n",
            "a a\n",
            "Correct world:a\n",
            "little littme\n",
            "Correct world:little\n",
            "bill bill\n",
            "Correct world:bill\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "v v\n",
            "Correct world:v\n",
            "advice advice\n",
            "Correct world:advice\n",
            "from from\n",
            "Correct world:from\n",
            "a a\n",
            "Correct world:a\n",
            "caterpillar raterpillac\n",
            "Correct world:caterpillar\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "vi vi\n",
            "Correct world:vi\n",
            "pig piz\n",
            "Correct world:pig\n",
            "and xnd\n",
            "Correct world:and\n",
            "pepper pepper\n",
            "Correct world:pepper\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "vii vii\n",
            "Correct world:vii\n",
            "a a\n",
            "Correct world:a\n",
            "mad amd\n",
            "Correct world:mad\n",
            "teaparty teaparty\n",
            "Correct world:teaparty\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "viii viii\n",
            "Correct world:viii\n",
            "the the\n",
            "Correct world:the\n",
            "queens zueens\n",
            "Correct world:queens\n",
            "croquetground croquetground\n",
            "Correct world:croquetground\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "iv ic\n",
            "Correct world:ix\n",
            "the the\n",
            "Correct world:the\n",
            "mock mock\n",
            "Correct world:mock\n",
            "turtles turtles\n",
            "Correct world:turtles\n",
            "story story\n",
            "Correct world:story\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "x x\n",
            "Correct world:x\n",
            "the the\n",
            "Correct world:the\n",
            "lobster lsboter\n",
            "Correct world:lobster\n",
            "quadrille quadrille\n",
            "Correct world:quadrille\n",
            "chapter chartep\n",
            "Correct world:chapter\n",
            "xi xi\n",
            "Correct world:xi\n",
            "who who\n",
            "Correct world:who\n",
            "stole stole\n",
            "Correct world:stole\n",
            "the eht\n",
            "Correct world:the\n",
            "tarts tarts\n",
            "Correct world:tarts\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "xii xii\n",
            "Correct world:xii\n",
            "alices alices\n",
            "Correct world:alices\n",
            "evidence nvideece\n",
            "Correct world:evidence\n",
            "chapter chapter\n",
            "Correct world:chapter\n",
            "i i\n",
            "Correct world:i\n",
            "dont donw\n",
            "Correct world:down\n",
            "the the\n",
            "Correct world:the\n",
            "rabbithole raebithole\n",
            "Correct world:rabbithole\n",
            "alice alice\n",
            "Correct world:alice\n",
            "was was\n",
            "Correct world:was\n",
            "beginning beginning\n",
            "Correct world:beginning\n",
            "to to\n",
            "Correct world:to\n",
            "get get\n",
            "Correct world:get\n",
            "very very\n",
            "Correct world:very\n",
            "tired tired\n",
            "Correct world:tired\n",
            "of of\n",
            "Correct world:of\n",
            "sitting sitting\n",
            "Correct world:sitting\n",
            "by by\n",
            "Correct world:by\n",
            "her her\n",
            "Correct world:her\n",
            "sister sister\n",
            "Correct world:sister\n",
            "0.759 0.907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFClxcZjlixb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}